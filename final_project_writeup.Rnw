\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{mathtools}
\usepackage{icomma}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\usepackage{mathpazo}
\frenchspacing
\MakeOuterQuote{"}
\setlength{\parindent}{0pt}
\usepackage{enumitem}
\newcommand{\Var}[1]{\text{Var}\left(#1\right)}
\newcommand{\Cov}[2]{\text{Cov}\left(#1, #2\right)}
\newcommand{\E}[1]{\mathbb{E}\left[#1\right]}

% remove section numbers
% https://tex.stackexchange.com/questions/136527/section-numbering-without-numbers
\makeatletter
\def\@seccntformat#1{%
  \expandafter\ifx\csname c@#1\endcsname\c@section\else
  \csname the#1\endcsname\quad
  \fi}
\makeatother

\usepackage{hyperref}

\begin{document}
\begin{center}
\textbf{Final Project Writeup}

STAT 580

Yeng Miller-Chang
\end{center}

\section{Mathematical Exposition}

\vspace{0.2cm}
Mathematically, my project is as follows:
\begin{center}
Given a $2 \times 2$ contingency table of counts with $\alpha \in (0, 1)$ fixed, generate a $100(1-\alpha)\%$ \underline{exact} confidence interval for the odds ratio for the table.
\end{center}
This problem, although seemingly simple at its surface, requires a substantial amount of computational work.

\vspace{0.2cm}
Suppose we have a $2 \times 2$ contingency table of proportions which constitute a probability distribution:
\begin{equation*}
\begin{array}{|c|c|}
\hline
\pi_{11} & \pi_{12} \\
\hline
\pi_{21} & \pi_{22} \\
\hline
\end{array}
\end{equation*}
The odds ratio is defined by $\theta = \dfrac{\pi_{11}\pi_{22}}{\pi_{12}\pi_{21}}$.\footnote{Agresti, A. (2013), \textit{Categorical Data Analysis}  (3rd ed.), Hoboken, NJ: John Wiley \& Sons, p. 606.}

\vspace{0.2cm}
Consider a $2 \times 2$ contingency table of counts derived from a sample:
\begin{equation*}
\begin{array}{|c|c|}
\hline
n_{11} & n_{12} \\
\hline
n_{21} & n_{22} \\
\hline
\end{array}
\end{equation*}
Let $+$ denote summation over indices; for example, $n_{+1} = \sum_{i=1}^{2}n_{i1}$, and $n_{++} = \sum_{i=1}^{2}\sum_{j=1}^{2}n_{ij}$. The sample odds ratio is defined by\footnote{Agresti, A. (2013), \textit{Categorical Data Analysis}  (3rd ed.), Hoboken, NJ: John Wiley \& Sons, p. 69.}
\begin{equation*}
\hat{\theta} = \dfrac{n_{11}n_{22}}{n_{21}n_{22}}\text{.}
\end{equation*}
It can be shown that, using a multinomial assumption, the Central Limit Theorem, and the Delta Method, that an approximate standard error for $\log(\hat{\theta})$ is \footnote{Agresti, A. (2013), \textit{Categorical Data Analysis}  (3rd ed.), Hoboken, NJ: John Wiley \& Sons, pp. 70-75.}
\begin{equation*}
\hat{\sigma}_{\hat{\theta}} = \sqrt{\dfrac{1}{n_{11}} + \dfrac{1}{n_{12}} + \dfrac{1}{n_{21}} + \dfrac{1}{n_{22}}}\text{.}
\end{equation*}
One could easily use the approximation above to generate $100(1-\alpha)\%$ confidence intervals for $\log(\theta)$ based on a normal approximation; however, this is only appropriate for large samples. Suppose that the above table has been stratified by a variable (say, for example, age), for which each value of said variable has its own $2 \times 2$ contingency table. As an example, suppose we have the following $2 \times 2$ contingency table:
\begin{equation*}
\begin{array}{|c|c|}
\hline
30 & 20\\
\hline
40 & 30 \\
\hline
\end{array}
\end{equation*}
and that we decide to stratify these data based on another factor:
\begin{align*}
\text{Group A} \qquad& \begin{array}{|c|c|}
\hline
20 & 15\\
\hline
10 & 15 \\
\hline
\end{array} \\
\text{Group B} \qquad& \begin{array}{|c|c|}
\hline
10 & 5\\
\hline
30 & 15 \\
\hline
\end{array}
\end{align*}
In cases such as the one above, it does not seem reasonable to use a normal approximation. Set $n = n_{++}$. It turns out that with the marginal totals given, it can be shown that $n_{11}$ has probability mass function
\begin{equation*}
f(t \mid n_{1+}, n_{+1}, n) = \dfrac{\displaystyle\binom{n_{1+}}{t} \binom{n-n_{1+}}{n_{+1} - t} \theta^t}{\displaystyle\sum_{u=m_{-}}^{m_{+}}\binom{n_{1+}}{u} \binom{n-n_{1+}}{n_{+1} - u} \theta^u}
\end{equation*}
for $m_{-} \leq t \leq m_{+}$ with $m_{-} = \max(0, n_{1+} + n_{+1} - n)$ and $m_{+} = \min(n_{1+}, n_{+1})$, which is of the "noncentral hypergeometric distribution." Cornfield (1956)\footnote{Cornfield, J. (1956), "A Statistical Problem Arising from Retrospective Studies," \textit{Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability}, 4, 135--148,  Berkeley, CA: University of California Press. Available at https://projecteuclid.org/euclid.bsmsp/1200502552.} provides one method to find a $100(1-\alpha)\%$ confidence interval for $\theta$: one could solve for $\theta_0$ and $\theta_1$ in the equations
\begin{equation*}
\dfrac{\alpha}{2} = \sum\limits_{t \geq n_{11}}f(t \mid n_{1+}, n_{+1}, n, \theta_1) = \sum\limits_{t \leq n_{11}}f(t \mid n_{1+}, n_{+1}, n, \theta_0)\text{.}
\end{equation*}
\section{Computational Exposition}
The crux of this problem is to find the roots of the following functions of $\theta$:
\begin{align*}
\sum\limits_{t \geq n_{11}}f(t \mid n_{1+}, n_{+1}, n, \theta) - \dfrac{\alpha}{2} &= \dfrac{\displaystyle\sum\limits_{t \geq n_{11}}\binom{n_{1+}}{t} \binom{n-n_{1+}}{n_{+1} - t} \theta^t}{\displaystyle\sum_{u=m_{-}}^{m_{+}}\binom{n_{1+}}{u} \binom{n-n_{1+}}{n_{+1} - u} \theta^u} - \dfrac{\alpha}{2}\\ 
\sum\limits_{t \leq n_{11}}f(t \mid n_{1+}, n_{+1}, n, \theta) - \dfrac{\alpha}{2} &= \dfrac{\displaystyle\sum\limits_{t \leq n_{11}}\binom{n_{1+}}{t} \binom{n-n_{1+}}{n_{+1} - t} \theta^t}{\displaystyle\sum_{u=m_{-}}^{m_{+}}\binom{n_{1+}}{u} \binom{n-n_{1+}}{n_{+1} - u} \theta^u} - \dfrac{\alpha}{2}\text{.}
\end{align*}
These two problems can be describe more succinctly as follows: let $\{a_t\}$ and $\{b_u\}$ be non-negative finite (with starting and stopping points) sequences. Then we wish to find the root of
\begin{equation}
\dfrac{\displaystyle\sum_{t} a_t \theta^t}{\displaystyle\sum_{u}b_u\theta^u} - \dfrac{\alpha}{2}\text{.} \label{problem-function}
\end{equation}
The function of $\theta$ above \eqref{problem-function} is problematic. First of all, it is not continuous at $\theta = 0$, and who knows where else it could be discontinuous? Note the denominator of the first fraction implies that the function above is discontinuous for all $\theta$ satisfying $\sum_{u}b_u\theta^u = 0$. Therefore, using Newton-Raphson on this function of $\theta$ above is quite risky. Furthermore, since we do not know anything about the powers of $\theta$ beforehand, we can't determine where the function of $\theta$ above will be positive or negative, so the bisection method is off limits.

\vspace{0.2cm}
\end{document}
